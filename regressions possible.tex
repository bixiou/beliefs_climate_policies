%% LyX 2.3.2 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[french]{article}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}

\makeatletter
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
\newcommand\independent{\protect\mathpalette{\protect\independenT}{\perp}}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}

\makeatother

\usepackage{babel}
\makeatletter
\addto\extrasfrench{%
   \providecommand{\og}{\leavevmode\flqq~}%
   \providecommand{\fg}{\ifdim\lastskip>\z@\unskip\fi~\frqq}%
}

\makeatother
\begin{document}
\title{Régressions possibles}
\maketitle

\section{Termes}

\subsection{Variables}
\begin{itemize}
\item $L^{\mathring{T}}$/$L^{\mathring{L}}$ perte\_relative\_partielle:
$\left[-2;+2\right]$ suite à hausse taxe partielle
\item $G^{p}$ gagnant\_partielle\_categorie: G/N/P suite à hausse taxe
partielle compensée
\item $G$ gagnant\_categorie: G/N/P suite à hausse taxe compensée
\item $g$ gain: $\left[-6;+5\right]$ suite à hausse taxe compensée
\item $A^{I}$ taxe\_approbation: Oui/Non/NSP approbation hausse taxe compensée
avant info (\emph{I} pour initial ou ignorant)
\item $P$ progressivite: Oui/Non/NSP hausse taxe compensée avantagerait
les plus modestes (seulement pour apres\_modifs)
\item $\widehat{\Gamma}$ simule\_gagnant: ménage simulé gagnant avec 5
chances sur 6 suite à hausse taxe compensée
\item $\widehat{\gamma}$ simule\_gain: gain simulé du ménage suite à hausse
taxe compensée
\item $G^{P}$/$G^{F}$: gagnant\_{[}progressif/feedback{]}\_categorie:
G/N/P suite à hausse taxe compensée et à affichage de l'info sur la
progressivité $I^{P}$ / simule\_gagnant $\widehat{\Gamma}$
\item $\widehat{\Gamma^{C}}$ simule\_gain\_cible: gain simulé du ménage
suite à hausse taxe compensée
\item $A^{P}$/$A^{F}$ taxe\_{[}progressif/feedback{]}\_approbation: Oui/Non/NSP
approbation hausse taxe compensée après info progressivité et/ou simule\_gagnant
($A^{r}$ pour renseigné)
\item $\pi$ categorie\_cible: /20/30/40/50/70/ catégorie de revenus du
répondant et de son ménage
\item $T$ (resp. $T_{2}$) traite\_cible: indicatrice que le répondant
(resp. son conjoint) reçoit un versement dans la taxe avec compensation
ciblée ($T=\left(R<c\right)$)
\item $\Theta$ (resp. $\Theta^{C}$) versement: versement reçu comme compensation
de la taxe
\item $G^{C}$ gagnant\_cible\_categorie: G/N/P suite à hausse taxe avec
compensation ciblée
\item $A^{C}$ taxe\_cible\_approbation: Oui/Non/NSP approbation hausse
taxe avec compensation ciblée
\item $R$ (resp. $R_{2}$): revenu (resp. revenu du conjoint)
\item $\mathbf{C}$: vecteur de contrôles
\item $\mathbf{E}$: caractéristiques énergétiques
\item $e$ (resp. $\overline{e}$): élasticité perso (resp. moyenne)
\item $\Delta E$ (resp. $\widehat{\Delta E}$): hausse des dépenses (resp.
estimées): $\Delta E=d\left(\mathbf{E}\right)\cdot\Delta\tau\cdot\left(1-e\right)$
\item $\Delta A^{v}=A^{v}-A^{I}$ pour $v\in\left\{ C;F;P\right\} $
\item $\Delta G^{v}=G^{v}-G$ pour $v\in\left\{ C;F\right\} $
\end{itemize}

\subsection{Réformes}
\begin{itemize}
\item $V$ hausse TVA
\item $\mathring{p}:\mathring{T},\mathring{L}$ hausse taxe partielle
\item $p:T,L$ hausse taxe partielle compensée
\item $\textrm{Ø}$ hausse taxe compensée
\item $C$ hausse taxe avec compensation ciblée (20/30/40/50 percentiles)
\end{itemize}

\subsection{Traitements}
\begin{itemize}
\item $p:T,L$ variante\_partielle: fuel ou chauffage 
\item $S$ apres\_modifs: 2è moitié: rajout de questions et d'information
sur la progressivité
\item $r:F,P$ variante\_feedback: f/p: feedback (2/3) / progressivité (1/3)
\item $I^{P}$ info\_progressivite: info sur la progressivité ((variante:
progressivité) ou (apres\_modifs et variante: feedback et variante\_progressivite:
fb\_info))
\item $c$ cible $\lessgtr$ $\pi$ categorie\_cible: cible attribuée aléatoirement
comme max ou min de categorie\_cible (sauf pour categorie\_cible=>70)
\end{itemize}

\section{Intérêt personnel}

\subsection{Gain subjectif avec ciblage}

\[
A_{i}^{C}=\delta_{0}+\beta_{G}G_{i}^{C}+\delta_{A}A_{i}^{I}+\epsilon_{i}
\]


\subsection{Discontinuité}

\[
A_{i}^{C}=\delta_{0}+\beta_{T}T_{i}+\beta_{2}T_{2,i}+\delta_{R}R_{i}+\epsilon_{i}
\]


\subsection{Discontinuité instrumentée}

\begin{align*}
G_{i}^{C} & =\alpha_{0}+\alpha_{T}T_{i}+\alpha_{2}T_{2,i}+\gamma_{A}A_{i}^{I}\left(+\gamma_{R}R_{i}\right)+\eta_{i}\\
A_{i}^{C} & =\delta_{0}+\beta_{G}\widehat{G_{i}^{C}}\left(+\sum_{c}\beta_{c}\mathbf{1}_{c_{i}=c}+\beta_{G\cdot c}\widehat{G_{i}^{C}}\mathbf{1}_{c_{i}=c}\right)+\delta_{A}A_{i}^{I}\left(+\delta_{R}R_{i}\right)+\epsilon_{i}
\end{align*}


\subsection{Simulation comme instrument (à travers $G^{F}$)}

introduire $A^{I}$ produit un effet

\begin{align*}
G_{i}^{F} & =\alpha_{0}+\widehat{\Gamma_{i}}+\gamma_{A}A_{i}^{I}+\gamma_{R}R_{i}+\eta_{i}\\
A_{i}^{F} & =\delta_{0}+\beta_{G}\widehat{G_{i}^{F}}+\delta_{A}A_{i}^{I}+\delta_{R}R_{i}+\epsilon_{i}
\end{align*}


\subsection{Simulation comme instrument (à travers $\Delta G^{F}$)}

introduire $A^{I}$ produit un effet

\begin{align*}
\Delta G_{i}^{F} & =\alpha_{0}+\widehat{\Gamma_{i}}+\gamma_{A}A_{i}^{I}+\gamma_{R}R_{i}+\eta_{i}\\
A_{i}^{F} & =\delta_{0}+\beta_{G}\widehat{\Delta G_{i}^{F}}+\delta_{A}A_{i}^{I}+\delta_{R}R_{i}+\epsilon_{i}
\end{align*}


\section{Persistance et biais des croyances}

\subsection{Persistance après la simulation}

\[
\Delta G_{i}^{F}=\alpha_{0}+\beta_{\Gamma}\widehat{\Gamma_{i}}+\mathbf{\beta_{C}C}_{i}+\epsilon_{i}
\]


\subsection{Simulation comme instrument}

\[
\Delta A_{i}^{F}=\alpha_{0}+\beta_{\Gamma}\widehat{\Gamma_{i}}+\mathbf{\beta_{C}C}_{i}+\epsilon_{i}
\]


\subsection{Biais de confirmation}

\[
\Delta A_{i}^{F}=\alpha_{0}+\beta_{j}G_{i}+\epsilon_{i}\,|\,\widehat{\Gamma_{i}}=j
\]


\subsection{Biais à la perte}

$U$: update\_correct vaut +1 si le répondant adopte le feedback qui
infirme sa croyance initiale, $-$1 s'il update contre le feedback
qui pourtant le confirme, 0 s'il n'update pas

\[
U_{i}=\alpha_{0}+\beta_{G}G_{i}^{F}\,|\,\widehat{\Gamma_{i}}\neq G_{i}
\]


\section{Modèle adaptatif bayésien}

On fait l'hypothèse que 
\[
\mathbb{P}_{i,t}\left(G_{i}>0\,|\,\mathbf{E}_{i}\right)=f\left(\underset{+}{\mathbb{E}\left[g_{i}\,|\,\mathbf{E}_{i}\right]}\right)=f\left(\gamma_{i}-b_{i}\right)
\]
et on estime \emph{f}. On a le gain subjectif $g_{i}=\gamma_{i}-b_{i}+\epsilon_{i}$
où l'erreur de l'individu \emph{i} par rapport au gain objectif $\gamma_{i}$
est $-b_{i}+\epsilon_{i}$, avec $\mathbb{E}\left[\epsilon_{i}\right]=0$
(et en espérant que $\mathbb{E}\left[\epsilon_{i}\,|\,\Delta\widehat{E_{i}}\right]=0$).
(On pourrait faire dépendre \emph{$b_{i}$ }de caractéristiques observables
dans une extension). On peut estimer le biais \emph{$b_{i}$ }directement.

\begin{align*}
g_{i} & =\underset{\gamma_{i}}{\underbrace{110-\Delta E_{i}}}-b_{i}+\epsilon_{i}\\
 & =\underset{\widehat{\gamma_{i}}}{\underbrace{110-\Delta\widehat{E_{i}}}}+\iota_{i}-b_{i}+\epsilon_{i}
\end{align*}

Le répondant sait qu'il commet une erreur $b_{i}-\epsilon_{i}$, qu'il
croit d'espérance nulle (il pense que $b_{i}=0$ \emph{a priori}).
Il croit que nous estimons ses hausses de dépenses à $\widehat{\gamma_{i}}-\epsilon_{i}=\gamma_{i}-\iota_{i}-\epsilon_{i}$,
et que nous commettons une erreur d'espérance $b_{i}-\iota_{i}$ \emph{a
priori }non nulle ($\widehat{\gamma_{i}}-\epsilon_{i}\tilde{\sim}\mathcal{N}\left(b-\iota_{i},\sigma^{2}\right)$),
où $\iota_{i}-b_{i}$ est son information partielle (liée à ses caractéristiques
inobservées par nous). On peut décomposer $b_{i}-\iota_{i}$ entre
son biais $b_{i}$ et le nôtre $\iota_{i}$ (qu'on peut estimer dans
une extension pour estimer \emph{b} plus précisément). Le répondant
sait qu'il peut être biaisé. Il sait que l'écart $g_{i}-\widehat{\gamma_{i}}$
entre son estimation et la nôtre est de $\iota_{i}-b_{i}+\epsilon_{i}$,
mais ne sait pas quel part de cet écart est dû à son information partielle
$\iota_{i}-b_{i}$, et quelle part est due à son incertitude $\epsilon_{i}$.
L'incertitude du répondant $\epsilon_{i}$ est une variable aléatoire
centrée qui l'empêche de distinguer son biais \emph{$b_{i}$} du nôtre
$\iota_{i}$.

Le feedback lui donne une information sur $\widehat{\gamma_{i}}$,
donc indirectement sur $\epsilon_{i}$. Après le feedback, il va réviser
son gain subjectif en

\[
g_{i}^{F}=\widehat{\gamma_{i}}+\iota_{i}-\left(\alpha+\eta_{i}\right)b_{i}+\epsilon_{i}
\]

$\alpha\in\left[0;1\right]$ ssi le répondant update dans le bon sens.
(On pourrait rendre le nouveau bruit $\eta_{i}b_{i}$ indépendant
de $b_{i}$, à voir\emph{ }en fonction des données).

$g_{i}^{F}$ n'est pas observée, mais on peut l'estimer à partir de
l'estimation de \emph{f} (et en regroupant des individus similaires):
\[
\widehat{g_{i}^{F}}=\widehat{f}^{-1}\left(\mathbb{P}_{i,t+1}\left(G_{i}^{F}>0\right)\right)
\]

Le paramètre qui nous intéresse est $\alpha$, car il représente l'ampleur
de la révision effectuée par le répondant. On l'estime en utilisant
$g_{i}-g_{i}^{F}=b_{i}\left(\alpha+\eta_{i}-1\right)$:

\begin{align*}
\widehat{\alpha} & =1+\frac{g_{i}-\widehat{g_{i}^{F}}}{b_{i}}
\end{align*}

Tentative de cadre bayésien :

\begin{align*}
\mathbb{P}_{i,t+1}\left(G_{i}^{F}>0\,|\,\widehat{\Gamma_{i}}>0,\mathbf{E}_{i}\right) & =f^{F}\left(\mathbb{E}\left[g_{i}^{F}\,|\,\mathbf{E}_{i}\right]\right)\\
 & =f^{F}\left(\gamma_{i}-\alpha b\right)\\
\mathbb{P}_{i,t+1}\left(G_{i}^{F}>0\,|\,\widehat{\Gamma_{i}}>0,\mathbf{E}_{i}\right) & =\frac{\mathbb{P}_{i,t}\left(G_{i}^{F}>0\,|\,\mathbf{E}_{i}\right)\mathbb{P}_{i,t}\left(\widehat{\Gamma_{i}}>0\,|\,G_{i}^{F}>0,\mathbf{E}_{i}\right)}{\mathbb{P}_{i,t}\left(\widehat{\Gamma_{i}}>0\,|\,\mathbf{E}_{i}\right)}\\
 & =\frac{f^{F}\left(\gamma_{i}-b\right)\mathbb{P}_{i,t}\left(\widehat{\Gamma_{i}}>0\,|\,G_{i}^{F}>0,\mathbf{E}_{i}\right)}{\mathbb{P}_{i,t}\left(\widehat{\Gamma_{i}}>0\,|\,\mathbf{E}_{i}\right)}\\
 & =\frac{f^{F}\left(\gamma_{i}-b\right)\mathbb{P}_{i,t}\left(\widehat{\Gamma_{i}}>0\,|\,\mathbf{E}_{i}\right)}{\mathbb{P}_{i,t}\left(\widehat{\Gamma_{i}}>0\,|\,\mathbf{E}_{i}\right)}\\
 & \overset{\text{hyp.}}{=}\frac{f^{F}\left(\gamma_{i}-b\right)\mathbb{P}_{i,t}\left(\widehat{\Gamma_{i}}>0\,|\,G_{i}^{F}>0,\mathbf{E}_{i}\right)}{\mathbb{P}_{i,t}\left(\Gamma_{i}>0\,|\,\mathbf{E}_{i}\right)}\\
\\
\widetilde{\mathbb{P}}_{i,t}\left(G_{i}>0\,|\,\mathbf{E}_{i}\right) & =f\left(g_{i}\right)\\
\widetilde{\mathbb{P}}_{i,t+1}\left(\Gamma_{i}>0\,|\,\widehat{\Gamma_{i}}>0,\mathbf{E}_{i}\right) & =\widetilde{\mathbb{P}}_{i,t}\left(\Gamma_{i}>0\,|\,\mathbf{E}_{i}\right)\frac{\widetilde{\mathbb{P}}_{i,t}\left(\widehat{\Gamma_{i}}>0\,|\,\Gamma_{i}>0,\mathbf{E}_{i}\right)}{\widetilde{\mathbb{P}}_{i,t}\left(\widehat{\Gamma_{i}}>0\,|\,\mathbf{E}_{i}\right)}\\
\widetilde{\mathbb{P}}_{i,t+1}\left(\gamma_{i}>0\,|\,\widehat{\gamma_{i}}>0,\mathbf{E}_{i}\right) & =\widetilde{\mathbb{P}}_{i,t}\left(\gamma_{i}>0\,|\,\mathbf{E}_{i}\right)\frac{\widetilde{\mathbb{P}}_{i,t}\left(\widehat{\gamma_{i}}>0\,|\,\gamma_{i}>0,\mathbf{E}_{i}\right)}{\widetilde{\mathbb{P}}_{i,t}\left(\widehat{\gamma_{i}}>0\,|\,\mathbf{E}_{i}\right)}\\
\mathbb{P}_{i,t+1}\left(\gamma_{i}>0\,|\,\widehat{\gamma_{i}}-\epsilon_{i}>0,\mathbf{E}_{i}\right) & =\widetilde{\mathbb{P}}_{i,t}\left(\gamma_{i}>0\,|\,\mathbf{E}_{i}\right)\frac{\mathbb{P}_{i,t}\left(\widehat{\gamma_{i}}-\epsilon_{i}>0\,|\,\gamma_{i}>0,\mathbf{E}_{i}\right)}{\mathbb{P}_{i,t}\left(\widehat{\gamma_{i}}-\epsilon_{i}>0\,|\,\mathbf{E}_{i}\right)}\\
 & \overset{\text{si trust}}{=}\frac{5}{6}\frac{\mathbb{P}_{i,t}\left(\gamma_{i}-\iota_{i}-\epsilon_{i}>0\,|\,\gamma_{i}>0,\mathbf{E}_{i}\right)}{\mathbb{P}_{i,t}\left(\widehat{\gamma_{i}}>\epsilon_{i}\,|\,\mathbf{E}_{i}\right)}\\
 & =\frac{5}{6}\frac{\mathbb{P}_{i,t}\left(g_{i}-\iota_{i}>\epsilon_{i}\,|\,g_{i}>\epsilon_{i},\mathbf{E}_{i}\right)}{\Phi\left(g_{i}-\iota_{i}\right)}\\
\\
\\
\\
 & \mathbb{P}_{i,t+1}\left(g_{i}^{F}>0\,|\,\widehat{\Gamma_{i}}>0\right)
\end{align*}

$g_{i}-\gamma_{i}=\epsilon_{i}\tilde{\sim}\mathcal{N}\left(b,\sigma^{2}\right)$, 

$\widehat{\gamma_{i}}-\epsilon_{i}\tilde{\sim}\mathcal{N}\left(b-\iota_{i},\sigma^{2}\right)$,
$b-\epsilon_{i}\tilde{\sim}\mathcal{N}\left(0,\sigma^{2}\right)$TODO:
mettre ça dans un cadre bayésien (le 5/6 n'intervient pas par exemple!).
Pistes : $\widetilde{\mathbb{P}}\left(\Gamma>0\right)\overset{\text{hyp.}}{=}\widetilde{\mathbb{P}}\left(\widehat{\Gamma}>0\right)\implies\widetilde{\mathbb{P}}\left(\widehat{\Gamma}>0\,|\,\Gamma>0\right)=\widetilde{\mathbb{P}}\left(\Gamma>0\,|\,\widehat{\Gamma}>0\right)=\frac{5}{6}$;
$\widetilde{\mathbb{P}}\left(\Gamma>0\right)$ peut être estimé/encadré
à partir de \emph{G }et $L^{\mathring{p}}$; $\widetilde{\mathbb{P}}\left(g_{i}^{F}>0\,|\,\widehat{\Gamma}>0\right)=\widetilde{\mathbb{P}}\left(\widehat{\gamma_{i}}+\iota_{i}-\left(\alpha+\eta_{i}\right)b>-\epsilon_{i}\,|\,\widehat{\gamma_{i}}>0\right)$...;
le répondant est certain quand il croit que $\text{Var}\left(\epsilon_{i}\right)$
est faible, mais alors après un feedback infirmant, il devrait soit
réviser son estimation fortement (car il se rend compte qu'un $\left|\epsilon_{i}\right|$
élevé est improbable): réviser \emph{b}, soit ça signifie qu'il croit
que notre estimation est fortement biaisée ($\widehat{\gamma_{i}}+\iota_{i}$,
avec $\left|\iota_{i}\right|$ élevé): réviser $\iota_{i}$ (cela
dénote une irrationalité ou un manque de confiance en nous, car la
révision devrait être vers $\iota_{i}=0$); on faisait l'hypothèse
que le répondant connaissait $\widehat{\gamma_{i}}$ mais on devrait
peut-être rajouter une erreur sur ce terme (ou interpréter $\iota_{i}$
ainsi).


\end{document}
